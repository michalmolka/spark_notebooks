{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "\r\n",
        "spark.sql(\"create database iowa\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "\r\n",
        "df = spark.read.load('abfss://iowabyyear@eightfive.dfs.core.windows.net/IowaLiquorSalesdf2022.parquet', format='parquet')\r\n",
        "df.write.mode(\"overwrite\").saveAsTable(\"iowa.Iowa2022\")\r\n",
        "iowa2022 = sqlContext.table(\"iowa.iowa2022\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "from pyspark.sql.types import StringType, DecimalType, IntegerType\r\n",
        "\r\n",
        "iowaPopulation = spark.read.load('abfss://iowafiles@eightfive.dfs.core.windows.net/IowaPopulation.csv', format='csv', header=True)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace, col, substring, length, split, lit\r\n",
        "from pyspark.sql.types import IntegerType\r\n",
        "\r\n",
        "iowaPopulationRefined = (\r\n",
        "    iowaPopulation\r\n",
        "        .withColumn(\"County\", \r\n",
        "            split(col(\"County\").substr(lit(2), length(col(\"County\"))), \" County\").getItem(0))\r\n",
        "         .withColumn(\"Population\", \r\n",
        "            regexp_replace(col(\"Population\"), \",\", \"\")\r\n",
        "            .astype(IntegerType()), \r\n",
        "        )\r\n",
        ")\r\n",
        "iowaPopulationRefined.write.mode(\"overwrite\").saveAsTable(\"iowa.iowapopulation\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(iowa2022.limit(5))\r\n",
        "iowa2022.printSchema()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(iowaPopulationRefined.limit(5))\r\n",
        "iowaPopulationRefined.printSchema()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower, sum, avg, col, initcap, round, date_format, trunc, first, row_number\r\n",
        "from pyspark.sql.window import Window\r\n",
        "\r\n",
        "rowNumberWindow = Window.partitionBy(col(\"Date\")).orderBy(col(\"County\"))\r\n",
        "sumWindow1 = Window.partitionBy(col(\"Date\"))\r\n",
        "\r\n",
        "iowa2022agg = (\r\n",
        "    iowa2022\r\n",
        "        .withColumn(\"County\", initcap(\"County\"))\r\n",
        "        .withColumn(\"Date\", trunc(col(\"Date\"), \"month\"))\r\n",
        "        .filter( (col(\"Date\").isNotNull()) & (col(\"Date\") >= \"2022-01-01\") )\r\n",
        "        .join(iowaPopulation, on=\"County\", how=\"leftouter\")\r\n",
        "        .groupBy(col(\"Date\"), col(\"County\"))\r\n",
        "        .agg(\r\n",
        "            round(sum(\"SaleDollars\")).alias(\"Sum of Sales\"), \r\n",
        "            round(avg(\"SaleDollars\"), 2).alias(\"Avg of Sales\"), \r\n",
        "            first(iowaPopulation[\"Population\"]).alias(\"Population\"))\r\n",
        "        .filter( (col(\"Sum of Sales\").between(10, 1000000)) & (col(\"County\").like(\"M%\")) )\r\n",
        "        .withColumn(\"Rank\", row_number().over(rowNumberWindow))\r\n",
        "        .withColumn(\"Sum per Month\", sum(col(\"Sum of Sales\")).over(sumWindow1))\r\n",
        "        .orderBy(col(\"Date\").desc(), col(\"County\").asc())\r\n",
        "        .show(20)\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "SELECT\r\n",
        "   TRUNC(i22.Date, \"MM\") AS `Date`\r\n",
        "  ,INITCAP(i22.County) AS `County`\r\n",
        "  ,ROUND(SUM(i22.SaleDollars)) AS `Sum of Sales`\r\n",
        "  ,ROUND(AVG(i22.SaleDollars), 2) AS `Avg of Sales`\r\n",
        "  ,FIRST(ip.Population) AS `Population`\r\n",
        "  ,ROW_NUMBER() OVER(PARTITION BY TRUNC(i22.Date, \"MM\") ORDER BY INITCAP(i22.County)) AS `Rank`\r\n",
        "  ,SUM(SUM(ROUND(i22.SaleDollars))) OVER(PARTITION BY TRUNC(i22.Date, \"MM\")) AS `Sum per Month`\r\n",
        "FROM iowa.iowa2022 i22\r\n",
        "LEFT JOIN iowa.iowapopulation ip\r\n",
        "    ON INITCAP(i22.County) = ip.County\r\n",
        "WHERE `Date` IS NOT NULL AND `Date` >= \"2022-01-01\"\r\n",
        "GROUP BY TRUNC(i22.Date, \"MM\"), INITCAP(i22.County)\r\n",
        "HAVING `Sum of Sales` BETWEEN 10 AND 1000000 AND `County` LIKE \"M%\"\r\n",
        "ORDER BY `Date` DESC, `County` ASC\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}